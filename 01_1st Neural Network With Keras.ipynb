{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Overview\n",
    "1. __讀取檔案__.\n",
    "2. __定義模型__.\n",
    "3. __編譯模型__.\n",
    "4. __擬合模型__.\n",
    "5. __評估模型__.\n",
    "6. __Summary__\n",
    "\n",
    "\n",
    "\n",
    "## 數據集 [這裡下載](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes):\n",
    "\n",
    "- 資料屬性:\n",
    "\n",
    "\n",
    "1. Number of times pregnant.  \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1)\n",
    "\n",
    "\n",
    "- 數據格式\n",
    "\n",
    "6, 148, 72, 35, 0, 33.6, 0.627, 50, 1\n",
    "\n",
    "1, 85, 66, 29, 0, 26.6, 0.351, 31, 0\n",
    "\n",
    "8, 183, 64, 0, 0, 23.3, 0.672, 32, 1\n",
    "\n",
    "1, 89, 66, 23, 94, 28.1, 0.167, 21, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.讀取檔案."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(87)\n",
    "\n",
    "# numpy讀檔函式 laodtxt\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.data.txt\", delimiter=\",\")\n",
    "\n",
    "# 分割檔案為，輸入/標籤\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#此為測試區！自行測試數據\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定義模型.\n",
    "\n",
    "- Keras疊積木時間。\n",
    "\n",
    "\n",
    "1. 宣告序列輸入\n",
    "2. 輸入8個，進入10個神經元隱藏層\n",
    "3. 10個再進入16個隱藏層\n",
    "4. 輸出1個位元\n",
    "\n",
    "    - keras神經網路權重weights初始化預設是，均勻分布0 ~ 0.05。\n",
    "    \n",
    "\n",
    "- Q : input_dim = 8 為什麼輸入神經元要設定成為8 ?\n",
    "- Q : 為什麼Activation 要用relu，但是最後卻是sigmoid？\n",
    "\n",
    "- A : 因為每次輸入數據有八個不同數值，sigmoid微分爆炸/消失有關， google **gradient vanish**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=8, activation='relu')) \n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.編譯模型.\n",
    "\n",
    "1. 我們使用的損失函數是：二位元交互訊息。盡可能最小損失。\n",
    "2. 優化方式： Adam\n",
    "3. 度量子：正確性。想辦法提高。\n",
    "\n",
    "Adam: A Method for Stochastic [Optimization]( http://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.擬合模型.\n",
    "\n",
    "- Hint :從768筆資料抽出幾筆(batch size)去做訓練，重複一次叫做一個epoch。\n",
    "\n",
    "- 參數可自行調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s - loss: 2.7916 - acc: 0.6693     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.8642 - acc: 0.6263     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.6582 - acc: 0.6549     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.6362 - acc: 0.6719     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6332 - acc: 0.6471     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6213 - acc: 0.6862     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6170 - acc: 0.6810     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.6111 - acc: 0.6810     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.6086 - acc: 0.6888     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.6045 - acc: 0.6823     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.6027 - acc: 0.6927     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.6043 - acc: 0.6823     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.5954 - acc: 0.6875     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.5925 - acc: 0.6914     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.5938 - acc: 0.7005     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.5915 - acc: 0.6745     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.5945 - acc: 0.6927     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.5914 - acc: 0.6927     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.5839 - acc: 0.6914     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.5818 - acc: 0.6992     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.5813 - acc: 0.6940     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.5861 - acc: 0.6914     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.5799 - acc: 0.6875     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.5762 - acc: 0.7018     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.5767 - acc: 0.6966     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.5705 - acc: 0.7174     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.5722 - acc: 0.7005     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.5731 - acc: 0.7031     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.5685 - acc: 0.7188     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.5654 - acc: 0.7214     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.5668 - acc: 0.7109     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.5647 - acc: 0.7083     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.5681 - acc: 0.6979     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.5673 - acc: 0.7070     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.5626 - acc: 0.7122     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.5676 - acc: 0.7018     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.5678 - acc: 0.7018     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.5683 - acc: 0.6979     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.5594 - acc: 0.7109     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.5548 - acc: 0.7148     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.5612 - acc: 0.7148     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.5594 - acc: 0.7057     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.5576 - acc: 0.7057     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.5541 - acc: 0.7135     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.5536 - acc: 0.7201     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.5505 - acc: 0.7266     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.5551 - acc: 0.7109     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.5578 - acc: 0.7083     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.5518 - acc: 0.7096     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.5509 - acc: 0.7227     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.5516 - acc: 0.7109     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.5512 - acc: 0.7227     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.5515 - acc: 0.7187     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.5453 - acc: 0.7214     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.5439 - acc: 0.7161     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.5484 - acc: 0.7227     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.5526 - acc: 0.7253     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.5413 - acc: 0.7318     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.5411 - acc: 0.7383     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.5413 - acc: 0.7318     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.5368 - acc: 0.7214     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.5367 - acc: 0.7174     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.5411 - acc: 0.7331     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.5385 - acc: 0.7318     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.5343 - acc: 0.7305     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.5342 - acc: 0.7344     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.5358 - acc: 0.7266     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.5324 - acc: 0.7305     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.5317 - acc: 0.7331     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.5310 - acc: 0.7266     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.5325 - acc: 0.7292     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.5234 - acc: 0.7422     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.5270 - acc: 0.7370     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.5268 - acc: 0.7370     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.5271 - acc: 0.7344     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.5278 - acc: 0.7331     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.5244 - acc: 0.7318     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.5177 - acc: 0.7487     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.5155 - acc: 0.7370     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.5285 - acc: 0.7344     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.5172 - acc: 0.7357     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.5184 - acc: 0.7422     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.5211 - acc: 0.7526     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.5154 - acc: 0.7435     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.5122 - acc: 0.7383     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.5128 - acc: 0.7331     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.5103 - acc: 0.7422     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.5163 - acc: 0.7448     \n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s - loss: 0.5094 - acc: 0.7487     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.5064 - acc: 0.7617     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.5079 - acc: 0.7487     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.5108 - acc: 0.7500     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.5135 - acc: 0.7396     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.5065 - acc: 0.7383     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.5043 - acc: 0.7500     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.5094 - acc: 0.7396     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.5072 - acc: 0.7409     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.4976 - acc: 0.7578     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.5040 - acc: 0.7396     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.4998 - acc: 0.7474     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.4989 - acc: 0.7552     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.5065 - acc: 0.7500     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.5052 - acc: 0.7422     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.5011 - acc: 0.7461     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.4975 - acc: 0.7526     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.4986 - acc: 0.7500     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.5080 - acc: 0.7461     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.4977 - acc: 0.7448     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.4962 - acc: 0.7578     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.4970 - acc: 0.7552     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.4944 - acc: 0.7591     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.4964 - acc: 0.7604     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.4954 - acc: 0.7669     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.4963 - acc: 0.7526     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.4901 - acc: 0.7734     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.4935 - acc: 0.7617     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.5010 - acc: 0.7461     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.4937 - acc: 0.7526     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.4977 - acc: 0.7448     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.4971 - acc: 0.7526     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.4888 - acc: 0.7656     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.4990 - acc: 0.7500     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.4931 - acc: 0.7487     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.4877 - acc: 0.7669     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.4914 - acc: 0.7539     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.4934 - acc: 0.7565     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.4861 - acc: 0.7669     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.4842 - acc: 0.7656     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.4857 - acc: 0.7695     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.4887 - acc: 0.7604     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.4891 - acc: 0.7630     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.4887 - acc: 0.7747     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.4897 - acc: 0.7669     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.4810 - acc: 0.7773     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.4817 - acc: 0.7643     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.4808 - acc: 0.7747     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.4860 - acc: 0.7682     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.4799 - acc: 0.7682     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.4898 - acc: 0.7591     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.4830 - acc: 0.7617     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.4807 - acc: 0.7682     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.4855 - acc: 0.7604     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.4756 - acc: 0.7669     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.4886 - acc: 0.7578     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.4752 - acc: 0.7721     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.4723 - acc: 0.7747     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.4814 - acc: 0.7682     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.4769 - acc: 0.7734     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.4787 - acc: 0.7760     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.4909 - acc: 0.7617     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119d34278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.評估模型\n",
    "\n",
    "我們訓練神經網路，在整個數據裡面，只會顯示出我們訓練的好壞，透過正確性來看，但是卻無法得知，訓練好的模型透用在新的數據上表現如何。\n",
    "簡單的做法就是，我們把數據拆解成，訓練/測試兩個數據，我們在這先把訓練好的模型，套用原先的數據，看看表現如何。\n",
    "\n",
    "- Q: 可以把原先數據再套用上去嗎？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0s\n",
      "acc: 77.34%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Summary\n",
    "\n",
    "1. 讀取檔案 numpy.loadtxt\n",
    "2. 定義模型 model = Sequential(), model.add()...\n",
    "    \n",
    "3. 編譯模型，損失函數，優化方式，度量方式\n",
    "4. 擬合 fit(X, Y, epochs=150, batch_size=10)\n",
    "5. 評估模型evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
